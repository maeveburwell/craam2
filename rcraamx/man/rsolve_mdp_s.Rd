% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{rsolve_mdp_s}
\alias{rsolve_mdp_s}
\title{Solves a robust Markov decision process with state rectangular
ambiguity sets. The worst-case is computed with the MDP transition
probabilities treated as nominal values.}
\usage{
rsolve_mdp_s(
  mdp,
  discount,
  nature,
  nature_par,
  algorithm = "mppi",
  policy_fixed = NULL,
  maxresidual = 0.001,
  iterations = 10000L,
  timeout = 300,
  value_init = NULL,
  pack_actions = FALSE,
  output_tran = FALSE,
  show_progress = 1L
)
}
\arguments{
\item{algorithm}{One of "ppi", "mppi", "mpi", "vi", "vi_j", "v_g", "pi". MPI may
may not converge}

\item{policy_fixed}{States for which the  policy should be fixed. This
should be a dataframe with columns idstate and idaction. The policy
is optimized only for states that are missing, and the fixed policy
is used otherwise}

\item{maxresidual}{Residual at which to terminate}

\item{iterations}{Maximum number of iterations}

\item{timeout}{Maximum number of secods for which to run the computation}

\item{value_init}{A  dataframe that contains the initial value function used
to initialize the method. The columns should be idstate and value.
Any states that are not provided are initialized to 0.}

\item{pack_actions}{Whether to remove actions with no transition probabilities,
and rename others for the same state to prevent gaps. The policy
for the original actions can be recovered using ``action_map'' frame
in the result}

\item{output_tran}{Whether to construct and return a matrix of transition
probabilites and a vector of rewards}

\item{show_progress}{Whether to show a progress bar during the computation.
0 means no progress, 1 is progress bar, and 2 is a detailed report}
}
\value{
A list with value function policy and other values
}
\description{
NOTE: The algorithms: pi, mpi may cycle infinitely without converging to a solution,
when solving a robust MDP.
The algorithms ppi and mppi are guaranteed to converge to an optimal solution.
}
\details{
Important: Worst-case transitions are allowed only to idstateto states that
are provided in the mdp dataframe, even when the transition
probability to those states is 0.



The options for nature and the corresponding nature_par are:
   \itemize{
        \item "l1u" an l1 ambiguity set with the same budget for all s.
               nature_par is a float number representing the budget
        \item "l1" an ambiguity set with different budgets for each s.
               nature_par is dataframe with idstate, budget
        \item "l1w" an l1-weighted ambiguity set with different weights
                     and budgets for each state and action
                nature_par is a list with two elements: budgets, weights.
                budgets must be a dataframe with columns idstate, budget
                and weights must be a dataframe with columns:
                idstatefrom, idaction, idstateto, weight (for the l1 weighted norms)
   }
}
